---
lab:
    title: 'Azure Databricks でデータを操作する'
    module: 'モジュール 1 - Azure Databricks の概要'
---

# Azure Databricks でデータを操作する

DBFS を使用してデータをロードし、Spark Dataframes を使用してデータを操作する方法を学習します。
Databricks ファイル システム (DBFS) は、Databricks ワークスペースにマウントされ、Databricks クラスターで使用できる分散ファイル システムです。
DataFrame　は、大量のデータの処理を可能にするデータの分散コレクションです。

## 前提条件

このラボを開始する前に、**Azure Databricks　の概要**のラボを完了して、Azure Databricks 環境をセットアップし、必要なデータとノートブックをインポートしてください。

## Azure Databricks でデータを操作する

この演習では、AzureDatabricks 環境内でデータを読み込んで操作する方法を学習します。

1. Web ブラウザーで、Azure Databricks ワークスペースを開きます。 

1. クラスターが実行されていない場合は、「**コンピューティング**」ページでクラスターを選択し、「**&#9654;開始**」ボタンを使用してクラスターを開始します

1. Azure Databricks ワークスペースで、左側のコマンド バーを使用して、「**ワークスペース**」を選択します。次に、「**ユーザー**」を選択し、**&#9751; *your_user_name*** を選択します。次に、**01 - Azure Databricks の概要**という名前のフォルダーで、**Azure Databricks でデータを操作する**のノートブックを開きます。

1. ノートブックをクラスターに接続します。次に、ノートブック内の注意事項を読み、各コード セルを順番に実行します。

## クリーンアップ

今のところ Azure Databricks の操作が終了している場合は、Azure Databricks ワークスペースの「**コンピューティング**」ページで、クラスターを選択し、「**&#9632;終了**」を選択して、シャットダウンします。それ以外の場合は、次の演習のために実行したままにします。
